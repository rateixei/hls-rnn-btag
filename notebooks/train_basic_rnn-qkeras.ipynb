{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593d1b5d-602d-4114-9cde-38a556384b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72db69d9-d7b7-42eb-b7f9-35b68cbe12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d559adc9-c581-4844-9c85-8acaba190879",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '/gpfs/slac/atlas/fs1/d/rafaeltl/public/ML/L1RNN/datasets_2020_ff/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba86bbc-b1fd-447e-91e6-5a7d76dc5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_str = 'Jan06_FlavFix_smear_1_std_xtd_zst.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b83ae3-ee13-4b67-8c36-e04d3eb3fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5 = h5py.File(data_loc+file_str, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6bd061c-822d-4ce2-9713-5bb92501c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array( f5['x_train'] )\n",
    "y_train = to_categorical ( np.array( f5['y_train'] ) )\n",
    "w_train = np.array( f5['w_train'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f7e97-b794-4599-8fe2-5321096774dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v2 as tf\n",
    "# tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c023e6e0-d2ed-49b1-bbdc-3d3ef426b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, LSTM, Masking, Input, GRU, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61fcc097-5f07-47dc-8478-a7ff98b666c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "386b5f6a-12cc-4020-9b38-4cb349756ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1bbc11d-901e-42b5-9398-546764855d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstmmodel(max_len, n_var, rec_units, ndense=[10], rec_layer='LSTM'):\n",
    "    \n",
    "    x = track_inputs = Input(shape=(max_len, n_var,))\n",
    "    \n",
    "    x = qkeras.QLSTM(\n",
    "                    rec_units,\n",
    "                    activation='quantized_tanh(4)',\n",
    "                    recurrent_activation='quantized_relu(4,0,1)',\n",
    "                    kernel_quantizer='stochastic_ternary(\"auto\")',\n",
    "                    recurrent_quantizer='quantized_bits(2,1,1,alpha=1.0)',\n",
    "                    bias_quantizer='quantized_bits(4,0,1)')(x)\n",
    "\n",
    "    \n",
    "    for ind,nd in enumerate(ndense):\n",
    "        x = qkeras.QDense(nd, \n",
    "                                kernel_quantizer=\"quantized_bits(4,0,1)\",\n",
    "                                bias_quantizer='quantized_bits(4,0,1)',\n",
    "                                name=f'dense_{ind}' )(x)\n",
    "        x = qkeras.QActivation('quantized_relu(4,0,1)')(x)\n",
    "    \n",
    "    output = qkeras.QDense(3, \n",
    "                            kernel_quantizer=\"quantized_bits(4,0,1)\",\n",
    "                            bias_quantizer='quantized_bits(4,0,1)', \n",
    "                           name = 'output_sigmoid')(x)\n",
    "    \n",
    "    output = qkeras.QActivation(\"quantized_bits(20, 5)\")(output)\n",
    "    \n",
    "    output = Activation('softmax')(output)\n",
    "    \n",
    "    model = Model(inputs=track_inputs, outputs=output)\n",
    "    \n",
    "    d_layers = ''.join([ str(dl) for dl in ndense ])\n",
    "#     mname = f'rnn_{rec_layer}_{rec_units}_{d_layers}_nomask'\n",
    "#     mname = f'rnn_{rec_layer}_{rec_units}_{d_layers}_nomask_LSTMKIvs' #LSTM kernel initializer variance scaling\n",
    "#     mname = f'rnn_{rec_layer}_{rec_units}_{d_layers}_nomask_LSTMKIgn' #LSTM kernel initializer glorot normal\n",
    "#     mname = f'rnn_{rec_layer}_{rec_units}_{d_layers}_nomask_LSTMKIvs_KRl10.001l20.0001' #LSTM kernel regularizer\n",
    "#     mname = f'rnn_{rec_layer}_{rec_units}_{d_layers}_nomask_LSTMKIvs_BRl111l21' #LSTM bias regularizer\n",
    "#     mname = f'rnn_{rec_layer}_{rec_units}_{d_layers}_nomask_LSTMKIvs_ARl11l21' #LSTM bias regularizer\n",
    "#     mname = f'rnn_{rec_layer}_{rec_units}_{d_layers}_nomask_LSTMKIvsReLu' #LSTM kernel regularizer\n",
    "\n",
    "    mname = f'Qrnn_{rec_layer}_{rec_units}_{d_layers}' #LSTM kernel regularizer\n",
    "    \n",
    "    return model, mname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b311a0a0-d17e-4706-bb52-505d6e9ea904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, model_name = lstmmodel(15, 6, 50, [10], rec_layer='GRU')\n",
    "model, model_name = lstmmodel(15, 6, 16, [80], rec_layer='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557bc024-1e18-406e-8b8d-01bfadaa576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 15, 6)]           0         \n",
      "_________________________________________________________________\n",
      "qlstm (QLSTM)                (None, 16)                1472      \n",
      "_________________________________________________________________\n",
      "dense_0 (QDense)             (None, 80)                1360      \n",
      "_________________________________________________________________\n",
      "q_activation (QActivation)   (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "output_sigmoid (QDense)      (None, 3)                 243       \n",
      "_________________________________________________________________\n",
      "q_activation_1 (QActivation) (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,075\n",
      "Trainable params: 3,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Qrnn_LSTM_16_80\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00755902-27ea-4bf6-ad60-08d3a5a388d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(f'keras/model_{model_name}_arch.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b51cdf-0ed6-4c79-bf29-951cac4b7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2b58af-8a8e-4002-ad45-84aeb8fe3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e41cf7-5fba-4d1a-878f-83e0f8a23379",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = f'keras/model_{model_name}_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba1de616-dc46-4fdc-8c72-fe71a9a8c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e28ff1dc-8ca3-4ed2-b26c-1f5480186782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0052 - accuracy: 0.4989\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53963, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 12s 313ms/step - loss: 1.0052 - accuracy: 0.4989 - val_loss: 0.9619 - val_accuracy: 0.5396\n",
      "Epoch 2/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9345 - accuracy: 0.5692\n",
      "Epoch 00002: val_accuracy improved from 0.53963 to 0.60483, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 8s 199ms/step - loss: 0.9345 - accuracy: 0.5692 - val_loss: 0.8973 - val_accuracy: 0.6048\n",
      "Epoch 3/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8856 - accuracy: 0.6186\n",
      "Epoch 00003: val_accuracy improved from 0.60483 to 0.63715, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.8856 - accuracy: 0.6186 - val_loss: 0.8641 - val_accuracy: 0.6371\n",
      "Epoch 4/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8567 - accuracy: 0.6411\n",
      "Epoch 00004: val_accuracy improved from 0.63715 to 0.64164, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 0.8567 - accuracy: 0.6411 - val_loss: 0.8512 - val_accuracy: 0.6416\n",
      "Epoch 5/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8358 - accuracy: 0.6536\n",
      "Epoch 00005: val_accuracy improved from 0.64164 to 0.66141, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 7s 184ms/step - loss: 0.8358 - accuracy: 0.6536 - val_loss: 0.8298 - val_accuracy: 0.6614\n",
      "Epoch 6/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8256 - accuracy: 0.6587\n",
      "Epoch 00006: val_accuracy improved from 0.66141 to 0.66745, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 0.8256 - accuracy: 0.6587 - val_loss: 0.8115 - val_accuracy: 0.6675\n",
      "Epoch 7/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8254 - accuracy: 0.6573\n",
      "Epoch 00007: val_accuracy did not improve from 0.66745\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 0.8254 - accuracy: 0.6573 - val_loss: 0.8265 - val_accuracy: 0.6599\n",
      "Epoch 8/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8226 - accuracy: 0.6584\n",
      "Epoch 00008: val_accuracy did not improve from 0.66745\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 0.8226 - accuracy: 0.6584 - val_loss: 0.8324 - val_accuracy: 0.6600\n",
      "Epoch 9/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.6590\n",
      "Epoch 00009: val_accuracy did not improve from 0.66745\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 0.8234 - accuracy: 0.6590 - val_loss: 0.8156 - val_accuracy: 0.6650\n",
      "Epoch 10/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8217 - accuracy: 0.6601\n",
      "Epoch 00010: val_accuracy did not improve from 0.66745\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 0.8217 - accuracy: 0.6601 - val_loss: 0.8201 - val_accuracy: 0.6619\n",
      "Epoch 11/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8151 - accuracy: 0.6642\n",
      "Epoch 00011: val_accuracy improved from 0.66745 to 0.66818, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 8s 198ms/step - loss: 0.8151 - accuracy: 0.6642 - val_loss: 0.8114 - val_accuracy: 0.6682\n",
      "Epoch 12/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8095 - accuracy: 0.6664\n",
      "Epoch 00012: val_accuracy improved from 0.66818 to 0.67010, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.8095 - accuracy: 0.6664 - val_loss: 0.8032 - val_accuracy: 0.6701\n",
      "Epoch 13/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8071 - accuracy: 0.6674\n",
      "Epoch 00013: val_accuracy did not improve from 0.67010\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 0.8071 - accuracy: 0.6674 - val_loss: 0.8162 - val_accuracy: 0.6580\n",
      "Epoch 14/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8068 - accuracy: 0.6691\n",
      "Epoch 00014: val_accuracy did not improve from 0.67010\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 0.8068 - accuracy: 0.6691 - val_loss: 0.8087 - val_accuracy: 0.6615\n",
      "Epoch 15/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8080 - accuracy: 0.6663\n",
      "Epoch 00015: val_accuracy did not improve from 0.67010\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.8080 - accuracy: 0.6663 - val_loss: 0.8174 - val_accuracy: 0.6575\n",
      "Epoch 16/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8037 - accuracy: 0.6689\n",
      "Epoch 00016: val_accuracy improved from 0.67010 to 0.67793, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 0.8037 - accuracy: 0.6689 - val_loss: 0.7949 - val_accuracy: 0.6779\n",
      "Epoch 17/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7978 - accuracy: 0.6722\n",
      "Epoch 00017: val_accuracy did not improve from 0.67793\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 0.7978 - accuracy: 0.6722 - val_loss: 0.7928 - val_accuracy: 0.6764\n",
      "Epoch 18/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7932 - accuracy: 0.6759\n",
      "Epoch 00018: val_accuracy did not improve from 0.67793\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 0.7932 - accuracy: 0.6759 - val_loss: 0.8058 - val_accuracy: 0.6717\n",
      "Epoch 19/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7929 - accuracy: 0.6769\n",
      "Epoch 00019: val_accuracy improved from 0.67793 to 0.68115, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 8s 197ms/step - loss: 0.7929 - accuracy: 0.6769 - val_loss: 0.7870 - val_accuracy: 0.6811\n",
      "Epoch 20/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.6785\n",
      "Epoch 00020: val_accuracy improved from 0.68115 to 0.68259, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 0.7895 - accuracy: 0.6785 - val_loss: 0.7883 - val_accuracy: 0.6826\n",
      "Epoch 21/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7881 - accuracy: 0.6784\n",
      "Epoch 00021: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.7881 - accuracy: 0.6784 - val_loss: 0.7951 - val_accuracy: 0.6747\n",
      "Epoch 22/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.6696\n",
      "Epoch 00022: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 0.8033 - accuracy: 0.6696 - val_loss: 0.7975 - val_accuracy: 0.6741\n",
      "Epoch 23/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8015 - accuracy: 0.6698\n",
      "Epoch 00023: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 0.8015 - accuracy: 0.6698 - val_loss: 0.8057 - val_accuracy: 0.6677\n",
      "Epoch 24/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7947 - accuracy: 0.6731\n",
      "Epoch 00024: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 0.7947 - accuracy: 0.6731 - val_loss: 0.7892 - val_accuracy: 0.6784\n",
      "Epoch 25/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8031 - accuracy: 0.6682\n",
      "Epoch 00025: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 0.8031 - accuracy: 0.6682 - val_loss: 0.8049 - val_accuracy: 0.6654\n",
      "Epoch 26/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.6733\n",
      "Epoch 00026: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 0.7967 - accuracy: 0.6733 - val_loss: 0.7933 - val_accuracy: 0.6758\n",
      "Epoch 27/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8000 - accuracy: 0.6715\n",
      "Epoch 00027: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 0.8000 - accuracy: 0.6715 - val_loss: 0.7930 - val_accuracy: 0.6747\n",
      "Epoch 28/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7951 - accuracy: 0.6740\n",
      "Epoch 00028: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 8s 197ms/step - loss: 0.7951 - accuracy: 0.6740 - val_loss: 0.7850 - val_accuracy: 0.6817\n",
      "Epoch 29/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7951 - accuracy: 0.6743\n",
      "Epoch 00029: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 0.7951 - accuracy: 0.6743 - val_loss: 0.8134 - val_accuracy: 0.6634\n",
      "Epoch 30/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8002 - accuracy: 0.6706\n",
      "Epoch 00030: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 0.8002 - accuracy: 0.6706 - val_loss: 0.7993 - val_accuracy: 0.6676\n",
      "Epoch 31/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7894 - accuracy: 0.6771\n",
      "Epoch 00031: val_accuracy did not improve from 0.68259\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 0.7894 - accuracy: 0.6771 - val_loss: 0.7952 - val_accuracy: 0.6775\n",
      "Epoch 32/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7929 - accuracy: 0.6758\n",
      "Epoch 00032: val_accuracy improved from 0.68259 to 0.68282, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 7s 191ms/step - loss: 0.7929 - accuracy: 0.6758 - val_loss: 0.7804 - val_accuracy: 0.6828\n",
      "Epoch 33/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.6751\n",
      "Epoch 00033: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 0.7963 - accuracy: 0.6751 - val_loss: 0.7881 - val_accuracy: 0.6810\n",
      "Epoch 34/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7904 - accuracy: 0.6782\n",
      "Epoch 00034: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 0.7904 - accuracy: 0.6782 - val_loss: 0.7946 - val_accuracy: 0.6785\n",
      "Epoch 35/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.6762\n",
      "Epoch 00035: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 0.7944 - accuracy: 0.6762 - val_loss: 0.7893 - val_accuracy: 0.6761\n",
      "Epoch 36/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7901 - accuracy: 0.6773\n",
      "Epoch 00036: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 0.7901 - accuracy: 0.6773 - val_loss: 0.7888 - val_accuracy: 0.6787\n",
      "Epoch 37/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.6705\n",
      "Epoch 00037: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 0.7997 - accuracy: 0.6705 - val_loss: 0.8027 - val_accuracy: 0.6703\n",
      "Epoch 38/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7912 - accuracy: 0.6757\n",
      "Epoch 00038: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 0.7912 - accuracy: 0.6757 - val_loss: 0.7875 - val_accuracy: 0.6799\n",
      "Epoch 39/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7937 - accuracy: 0.6736\n",
      "Epoch 00039: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 0.7937 - accuracy: 0.6736 - val_loss: 0.7962 - val_accuracy: 0.6711\n",
      "Epoch 40/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7974 - accuracy: 0.6723\n",
      "Epoch 00040: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 181ms/step - loss: 0.7974 - accuracy: 0.6723 - val_loss: 0.7869 - val_accuracy: 0.6799\n",
      "Epoch 41/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7989 - accuracy: 0.6711\n",
      "Epoch 00041: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 0.7989 - accuracy: 0.6711 - val_loss: 0.7914 - val_accuracy: 0.6747\n",
      "Epoch 42/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7931 - accuracy: 0.6730\n",
      "Epoch 00042: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 0.7931 - accuracy: 0.6730 - val_loss: 0.7839 - val_accuracy: 0.6802\n",
      "Epoch 43/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7906 - accuracy: 0.6758\n",
      "Epoch 00043: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 0.7906 - accuracy: 0.6758 - val_loss: 0.7947 - val_accuracy: 0.6750\n",
      "Epoch 44/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7968 - accuracy: 0.6725\n",
      "Epoch 00044: val_accuracy did not improve from 0.68282\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 0.7968 - accuracy: 0.6725 - val_loss: 0.7922 - val_accuracy: 0.6753\n",
      "Epoch 45/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.6721\n",
      "Epoch 00045: val_accuracy improved from 0.68282 to 0.68343, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 0.7976 - accuracy: 0.6721 - val_loss: 0.7833 - val_accuracy: 0.6834\n",
      "Epoch 46/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7937 - accuracy: 0.6747\n",
      "Epoch 00046: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7937 - accuracy: 0.6747 - val_loss: 0.7854 - val_accuracy: 0.6816\n",
      "Epoch 47/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.6715\n",
      "Epoch 00047: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7963 - accuracy: 0.6715 - val_loss: 0.7874 - val_accuracy: 0.6792\n",
      "Epoch 48/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7903 - accuracy: 0.6765\n",
      "Epoch 00048: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 0.7903 - accuracy: 0.6765 - val_loss: 0.7839 - val_accuracy: 0.6817\n",
      "Epoch 49/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7926 - accuracy: 0.6746\n",
      "Epoch 00049: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7926 - accuracy: 0.6746 - val_loss: 0.7948 - val_accuracy: 0.6712\n",
      "Epoch 50/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.6738\n",
      "Epoch 00050: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7944 - accuracy: 0.6738 - val_loss: 0.7822 - val_accuracy: 0.6797\n",
      "Epoch 51/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7981 - accuracy: 0.6707\n",
      "Epoch 00051: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 216ms/step - loss: 0.7981 - accuracy: 0.6707 - val_loss: 0.7912 - val_accuracy: 0.6740\n",
      "Epoch 52/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7970 - accuracy: 0.6722\n",
      "Epoch 00052: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7970 - accuracy: 0.6722 - val_loss: 0.8229 - val_accuracy: 0.6516\n",
      "Epoch 53/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.6718\n",
      "Epoch 00053: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7967 - accuracy: 0.6718 - val_loss: 0.7925 - val_accuracy: 0.6741\n",
      "Epoch 54/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.6690\n",
      "Epoch 00054: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 197ms/step - loss: 0.8033 - accuracy: 0.6690 - val_loss: 0.8065 - val_accuracy: 0.6679\n",
      "Epoch 55/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.6762\n",
      "Epoch 00055: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 0.7893 - accuracy: 0.6762 - val_loss: 0.7993 - val_accuracy: 0.6711\n",
      "Epoch 56/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7940 - accuracy: 0.6741\n",
      "Epoch 00056: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 7s 191ms/step - loss: 0.7940 - accuracy: 0.6741 - val_loss: 0.7887 - val_accuracy: 0.6805\n",
      "Epoch 57/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.6740\n",
      "Epoch 00057: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 197ms/step - loss: 0.7963 - accuracy: 0.6740 - val_loss: 0.7966 - val_accuracy: 0.6726\n",
      "Epoch 58/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7940 - accuracy: 0.6738\n",
      "Epoch 00058: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 209ms/step - loss: 0.7940 - accuracy: 0.6738 - val_loss: 0.8192 - val_accuracy: 0.6596\n",
      "Epoch 59/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7935 - accuracy: 0.6734\n",
      "Epoch 00059: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 205ms/step - loss: 0.7935 - accuracy: 0.6734 - val_loss: 0.7921 - val_accuracy: 0.6739\n",
      "Epoch 60/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.6723\n",
      "Epoch 00060: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7967 - accuracy: 0.6723 - val_loss: 0.8003 - val_accuracy: 0.6722\n",
      "Epoch 61/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.6697\n",
      "Epoch 00061: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 209ms/step - loss: 0.7991 - accuracy: 0.6697 - val_loss: 0.7963 - val_accuracy: 0.6721\n",
      "Epoch 62/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.6737\n",
      "Epoch 00062: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 0.7944 - accuracy: 0.6737 - val_loss: 0.8007 - val_accuracy: 0.6655\n",
      "Epoch 63/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7957 - accuracy: 0.6715\n",
      "Epoch 00063: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 205ms/step - loss: 0.7957 - accuracy: 0.6715 - val_loss: 0.7946 - val_accuracy: 0.6730\n",
      "Epoch 64/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.6742\n",
      "Epoch 00064: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7933 - accuracy: 0.6742 - val_loss: 0.7854 - val_accuracy: 0.6799\n",
      "Epoch 65/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7923 - accuracy: 0.6733\n",
      "Epoch 00065: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 0.7923 - accuracy: 0.6733 - val_loss: 0.7914 - val_accuracy: 0.6778\n",
      "Epoch 66/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8005 - accuracy: 0.6700\n",
      "Epoch 00066: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 0.8005 - accuracy: 0.6700 - val_loss: 0.8016 - val_accuracy: 0.6707\n",
      "Epoch 67/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7941 - accuracy: 0.6721\n",
      "Epoch 00067: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 0.7941 - accuracy: 0.6721 - val_loss: 0.7947 - val_accuracy: 0.6758\n",
      "Epoch 68/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7968 - accuracy: 0.6705\n",
      "Epoch 00068: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7968 - accuracy: 0.6705 - val_loss: 0.7955 - val_accuracy: 0.6785\n",
      "Epoch 69/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7977 - accuracy: 0.6722\n",
      "Epoch 00069: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 211ms/step - loss: 0.7977 - accuracy: 0.6722 - val_loss: 0.7899 - val_accuracy: 0.6791\n",
      "Epoch 70/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7989 - accuracy: 0.6694\n",
      "Epoch 00070: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 0.7989 - accuracy: 0.6694 - val_loss: 0.7903 - val_accuracy: 0.6750\n",
      "Epoch 71/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.6707\n",
      "Epoch 00071: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7991 - accuracy: 0.6707 - val_loss: 0.7868 - val_accuracy: 0.6768\n",
      "Epoch 72/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7909 - accuracy: 0.6742\n",
      "Epoch 00072: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7909 - accuracy: 0.6742 - val_loss: 0.7968 - val_accuracy: 0.6728\n",
      "Epoch 73/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7927 - accuracy: 0.6733\n",
      "Epoch 00073: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 0.7927 - accuracy: 0.6733 - val_loss: 0.8133 - val_accuracy: 0.6553\n",
      "Epoch 74/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7931 - accuracy: 0.6728\n",
      "Epoch 00074: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 0.7931 - accuracy: 0.6728 - val_loss: 0.7841 - val_accuracy: 0.6789\n",
      "Epoch 75/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7938 - accuracy: 0.6731\n",
      "Epoch 00075: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7938 - accuracy: 0.6731 - val_loss: 0.7996 - val_accuracy: 0.6730\n",
      "Epoch 76/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7966 - accuracy: 0.6712\n",
      "Epoch 00076: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 0.7966 - accuracy: 0.6712 - val_loss: 0.8049 - val_accuracy: 0.6652\n",
      "Epoch 77/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7978 - accuracy: 0.6713\n",
      "Epoch 00077: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 0.7978 - accuracy: 0.6713 - val_loss: 0.7884 - val_accuracy: 0.6741\n",
      "Epoch 78/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7932 - accuracy: 0.6742\n",
      "Epoch 00078: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7932 - accuracy: 0.6742 - val_loss: 0.7913 - val_accuracy: 0.6752\n",
      "Epoch 79/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7946 - accuracy: 0.6733\n",
      "Epoch 00079: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 204ms/step - loss: 0.7946 - accuracy: 0.6733 - val_loss: 0.8032 - val_accuracy: 0.6664\n",
      "Epoch 80/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7931 - accuracy: 0.6737\n",
      "Epoch 00080: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 0.7931 - accuracy: 0.6737 - val_loss: 0.7943 - val_accuracy: 0.6722\n",
      "Epoch 81/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7981 - accuracy: 0.6702\n",
      "Epoch 00081: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 202ms/step - loss: 0.7981 - accuracy: 0.6702 - val_loss: 0.7916 - val_accuracy: 0.6759\n",
      "Epoch 82/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7979 - accuracy: 0.6689\n",
      "Epoch 00082: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7979 - accuracy: 0.6689 - val_loss: 0.8023 - val_accuracy: 0.6690\n",
      "Epoch 83/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7954 - accuracy: 0.6707\n",
      "Epoch 00083: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7954 - accuracy: 0.6707 - val_loss: 0.8020 - val_accuracy: 0.6679\n",
      "Epoch 84/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7939 - accuracy: 0.6721\n",
      "Epoch 00084: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 209ms/step - loss: 0.7939 - accuracy: 0.6721 - val_loss: 0.7867 - val_accuracy: 0.6766\n",
      "Epoch 85/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.6721\n",
      "Epoch 00085: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 201ms/step - loss: 0.7963 - accuracy: 0.6721 - val_loss: 0.7855 - val_accuracy: 0.6821\n",
      "Epoch 86/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7969 - accuracy: 0.6719\n",
      "Epoch 00086: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7969 - accuracy: 0.6719 - val_loss: 0.7939 - val_accuracy: 0.6740\n",
      "Epoch 87/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7984 - accuracy: 0.6697\n",
      "Epoch 00087: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 0.7984 - accuracy: 0.6697 - val_loss: 0.7989 - val_accuracy: 0.6762\n",
      "Epoch 88/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7960 - accuracy: 0.6733\n",
      "Epoch 00088: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 0.7960 - accuracy: 0.6733 - val_loss: 0.7989 - val_accuracy: 0.6737\n",
      "Epoch 89/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7938 - accuracy: 0.6731\n",
      "Epoch 00089: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7938 - accuracy: 0.6731 - val_loss: 0.7928 - val_accuracy: 0.6746\n",
      "Epoch 90/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7983 - accuracy: 0.6706\n",
      "Epoch 00090: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 205ms/step - loss: 0.7983 - accuracy: 0.6706 - val_loss: 0.7952 - val_accuracy: 0.6757\n",
      "Epoch 91/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8065 - accuracy: 0.6658\n",
      "Epoch 00091: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 198ms/step - loss: 0.8065 - accuracy: 0.6658 - val_loss: 0.7926 - val_accuracy: 0.6736\n",
      "Epoch 92/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.6693\n",
      "Epoch 00092: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 204ms/step - loss: 0.8011 - accuracy: 0.6693 - val_loss: 0.7979 - val_accuracy: 0.6718\n",
      "Epoch 93/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8034 - accuracy: 0.6674\n",
      "Epoch 00093: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 0.8034 - accuracy: 0.6674 - val_loss: 0.7927 - val_accuracy: 0.6743\n",
      "Epoch 94/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.6751\n",
      "Epoch 00094: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 197ms/step - loss: 0.7924 - accuracy: 0.6751 - val_loss: 0.7826 - val_accuracy: 0.6792\n",
      "Epoch 95/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7964 - accuracy: 0.6725\n",
      "Epoch 00095: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 199ms/step - loss: 0.7964 - accuracy: 0.6725 - val_loss: 0.7990 - val_accuracy: 0.6745\n",
      "Epoch 96/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7960 - accuracy: 0.6733\n",
      "Epoch 00096: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 8s 214ms/step - loss: 0.7960 - accuracy: 0.6733 - val_loss: 0.7949 - val_accuracy: 0.6713\n",
      "Epoch 97/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7906 - accuracy: 0.6761\n",
      "Epoch 00097: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 9s 220ms/step - loss: 0.7906 - accuracy: 0.6761 - val_loss: 0.7906 - val_accuracy: 0.6765\n",
      "Epoch 98/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7941 - accuracy: 0.6727\n",
      "Epoch 00098: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 9s 235ms/step - loss: 0.7941 - accuracy: 0.6727 - val_loss: 0.8023 - val_accuracy: 0.6763\n",
      "Epoch 99/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.6726\n",
      "Epoch 00099: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.7942 - accuracy: 0.6726 - val_loss: 0.7932 - val_accuracy: 0.6769\n",
      "Epoch 100/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.6733\n",
      "Epoch 00100: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.7924 - accuracy: 0.6733 - val_loss: 0.7906 - val_accuracy: 0.6805\n",
      "Epoch 101/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7968 - accuracy: 0.6720\n",
      "Epoch 00101: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 267ms/step - loss: 0.7968 - accuracy: 0.6720 - val_loss: 0.7950 - val_accuracy: 0.6707\n",
      "Epoch 102/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8014 - accuracy: 0.6696\n",
      "Epoch 00102: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 0.8014 - accuracy: 0.6696 - val_loss: 0.8053 - val_accuracy: 0.6642\n",
      "Epoch 103/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7969 - accuracy: 0.6709\n",
      "Epoch 00103: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 11s 281ms/step - loss: 0.7969 - accuracy: 0.6709 - val_loss: 0.8378 - val_accuracy: 0.6459\n",
      "Epoch 104/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8028 - accuracy: 0.6688\n",
      "Epoch 00104: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 12s 297ms/step - loss: 0.8028 - accuracy: 0.6688 - val_loss: 0.7878 - val_accuracy: 0.6779\n",
      "Epoch 105/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8053 - accuracy: 0.6652\n",
      "Epoch 00105: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 12s 301ms/step - loss: 0.8053 - accuracy: 0.6652 - val_loss: 0.8035 - val_accuracy: 0.6700\n",
      "Epoch 106/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.6717\n",
      "Epoch 00106: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 12s 296ms/step - loss: 0.7965 - accuracy: 0.6717 - val_loss: 0.7905 - val_accuracy: 0.6756\n",
      "Epoch 107/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.6729\n",
      "Epoch 00107: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 267ms/step - loss: 0.7942 - accuracy: 0.6729 - val_loss: 0.7941 - val_accuracy: 0.6737\n",
      "Epoch 108/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7921 - accuracy: 0.6753\n",
      "Epoch 00108: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 11s 278ms/step - loss: 0.7921 - accuracy: 0.6753 - val_loss: 0.7981 - val_accuracy: 0.6754\n",
      "Epoch 109/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7964 - accuracy: 0.6730\n",
      "Epoch 00109: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 11s 273ms/step - loss: 0.7964 - accuracy: 0.6730 - val_loss: 0.8098 - val_accuracy: 0.6672\n",
      "Epoch 110/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8074 - accuracy: 0.6673\n",
      "Epoch 00110: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.8074 - accuracy: 0.6673 - val_loss: 0.7982 - val_accuracy: 0.6717\n",
      "Epoch 111/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7970 - accuracy: 0.6706\n",
      "Epoch 00111: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.7970 - accuracy: 0.6706 - val_loss: 0.8004 - val_accuracy: 0.6681\n",
      "Epoch 112/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7982 - accuracy: 0.6708\n",
      "Epoch 00112: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.7982 - accuracy: 0.6708 - val_loss: 0.7982 - val_accuracy: 0.6728\n",
      "Epoch 113/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7999 - accuracy: 0.6706\n",
      "Epoch 00113: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.7999 - accuracy: 0.6706 - val_loss: 0.7934 - val_accuracy: 0.6740\n",
      "Epoch 114/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7950 - accuracy: 0.6734\n",
      "Epoch 00114: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 11s 273ms/step - loss: 0.7950 - accuracy: 0.6734 - val_loss: 0.8016 - val_accuracy: 0.6686\n",
      "Epoch 115/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7927 - accuracy: 0.6740\n",
      "Epoch 00115: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 9s 232ms/step - loss: 0.7927 - accuracy: 0.6740 - val_loss: 0.7954 - val_accuracy: 0.6743\n",
      "Epoch 116/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7931 - accuracy: 0.6734\n",
      "Epoch 00116: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 9s 227ms/step - loss: 0.7931 - accuracy: 0.6734 - val_loss: 0.7974 - val_accuracy: 0.6715\n",
      "Epoch 117/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7880 - accuracy: 0.6770\n",
      "Epoch 00117: val_accuracy did not improve from 0.68343\n",
      "39/39 [==============================] - 9s 231ms/step - loss: 0.7880 - accuracy: 0.6770 - val_loss: 0.7891 - val_accuracy: 0.6771\n",
      "Epoch 118/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.6768\n",
      "Epoch 00118: val_accuracy improved from 0.68343 to 0.68366, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 9s 230ms/step - loss: 0.7879 - accuracy: 0.6768 - val_loss: 0.7769 - val_accuracy: 0.6837\n",
      "Epoch 119/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7853 - accuracy: 0.6788\n",
      "Epoch 00119: val_accuracy did not improve from 0.68366\n",
      "39/39 [==============================] - 9s 227ms/step - loss: 0.7853 - accuracy: 0.6788 - val_loss: 0.7854 - val_accuracy: 0.6822\n",
      "Epoch 120/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7888 - accuracy: 0.6770\n",
      "Epoch 00120: val_accuracy did not improve from 0.68366\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 0.7888 - accuracy: 0.6770 - val_loss: 0.7836 - val_accuracy: 0.6800\n",
      "Epoch 121/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7836 - accuracy: 0.6795\n",
      "Epoch 00121: val_accuracy improved from 0.68366 to 0.68664, saving model to keras/model_Qrnn_LSTM_16_80_weights.h5\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 0.7836 - accuracy: 0.6795 - val_loss: 0.7734 - val_accuracy: 0.6866\n",
      "Epoch 122/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7787 - accuracy: 0.6824\n",
      "Epoch 00122: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 0.7787 - accuracy: 0.6824 - val_loss: 0.7901 - val_accuracy: 0.6808\n",
      "Epoch 123/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7860 - accuracy: 0.6783\n",
      "Epoch 00123: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 204ms/step - loss: 0.7860 - accuracy: 0.6783 - val_loss: 0.7893 - val_accuracy: 0.6769\n",
      "Epoch 124/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.6768\n",
      "Epoch 00124: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 198ms/step - loss: 0.7879 - accuracy: 0.6768 - val_loss: 0.7870 - val_accuracy: 0.6775\n",
      "Epoch 125/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7811 - accuracy: 0.6811\n",
      "Epoch 00125: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 7s 191ms/step - loss: 0.7811 - accuracy: 0.6811 - val_loss: 0.7813 - val_accuracy: 0.6818\n",
      "Epoch 126/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.6761\n",
      "Epoch 00126: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 204ms/step - loss: 0.7879 - accuracy: 0.6761 - val_loss: 0.7882 - val_accuracy: 0.6782\n",
      "Epoch 127/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7882 - accuracy: 0.6757\n",
      "Epoch 00127: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 0.7882 - accuracy: 0.6757 - val_loss: 0.8107 - val_accuracy: 0.6647\n",
      "Epoch 128/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8166 - accuracy: 0.6603\n",
      "Epoch 00128: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.8166 - accuracy: 0.6603 - val_loss: 0.8011 - val_accuracy: 0.6690\n",
      "Epoch 129/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7938 - accuracy: 0.6734\n",
      "Epoch 00129: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7938 - accuracy: 0.6734 - val_loss: 0.7838 - val_accuracy: 0.6812\n",
      "Epoch 130/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.6780\n",
      "Epoch 00130: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7872 - accuracy: 0.6780 - val_loss: 0.8041 - val_accuracy: 0.6696\n",
      "Epoch 131/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7906 - accuracy: 0.6744\n",
      "Epoch 00131: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 204ms/step - loss: 0.7906 - accuracy: 0.6744 - val_loss: 0.7886 - val_accuracy: 0.6758\n",
      "Epoch 132/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7928 - accuracy: 0.6730\n",
      "Epoch 00132: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 201ms/step - loss: 0.7928 - accuracy: 0.6730 - val_loss: 0.8090 - val_accuracy: 0.6615\n",
      "Epoch 133/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7950 - accuracy: 0.6723\n",
      "Epoch 00133: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 204ms/step - loss: 0.7950 - accuracy: 0.6723 - val_loss: 0.7881 - val_accuracy: 0.6773\n",
      "Epoch 134/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7861 - accuracy: 0.6781\n",
      "Epoch 00134: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 210ms/step - loss: 0.7861 - accuracy: 0.6781 - val_loss: 0.7878 - val_accuracy: 0.6769\n",
      "Epoch 135/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7969 - accuracy: 0.6710\n",
      "Epoch 00135: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7969 - accuracy: 0.6710 - val_loss: 0.7963 - val_accuracy: 0.6760\n",
      "Epoch 136/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7972 - accuracy: 0.6712\n",
      "Epoch 00136: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 0.7972 - accuracy: 0.6712 - val_loss: 0.7922 - val_accuracy: 0.6764\n",
      "Epoch 137/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7941 - accuracy: 0.6736\n",
      "Epoch 00137: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7941 - accuracy: 0.6736 - val_loss: 0.8003 - val_accuracy: 0.6691\n",
      "Epoch 138/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7899 - accuracy: 0.6752\n",
      "Epoch 00138: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 0.7899 - accuracy: 0.6752 - val_loss: 0.7818 - val_accuracy: 0.6801\n",
      "Epoch 139/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7881 - accuracy: 0.6756\n",
      "Epoch 00139: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 0.7881 - accuracy: 0.6756 - val_loss: 0.7824 - val_accuracy: 0.6784\n",
      "Epoch 140/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7873 - accuracy: 0.6757\n",
      "Epoch 00140: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 0.7873 - accuracy: 0.6757 - val_loss: 0.7835 - val_accuracy: 0.6777\n",
      "Epoch 141/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7897 - accuracy: 0.6738\n",
      "Epoch 00141: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 0.7897 - accuracy: 0.6738 - val_loss: 0.7937 - val_accuracy: 0.6751\n",
      "Epoch 142/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7966 - accuracy: 0.6713\n",
      "Epoch 00142: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 0.7966 - accuracy: 0.6713 - val_loss: 0.8313 - val_accuracy: 0.6537\n",
      "Epoch 143/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7969 - accuracy: 0.6710\n",
      "Epoch 00143: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 209ms/step - loss: 0.7969 - accuracy: 0.6710 - val_loss: 0.7922 - val_accuracy: 0.6730\n",
      "Epoch 144/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7931 - accuracy: 0.6728\n",
      "Epoch 00144: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 214ms/step - loss: 0.7931 - accuracy: 0.6728 - val_loss: 0.8002 - val_accuracy: 0.6690\n",
      "Epoch 145/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7962 - accuracy: 0.6716\n",
      "Epoch 00145: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 0.7962 - accuracy: 0.6716 - val_loss: 0.7882 - val_accuracy: 0.6749\n",
      "Epoch 146/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7969 - accuracy: 0.6714\n",
      "Epoch 00146: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 0.7969 - accuracy: 0.6714 - val_loss: 0.8164 - val_accuracy: 0.6607\n",
      "Epoch 147/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7960 - accuracy: 0.6728\n",
      "Epoch 00147: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 0.7960 - accuracy: 0.6728 - val_loss: 0.7849 - val_accuracy: 0.6774\n",
      "Epoch 148/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7959 - accuracy: 0.6708\n",
      "Epoch 00148: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 8s 192ms/step - loss: 0.7959 - accuracy: 0.6708 - val_loss: 0.7871 - val_accuracy: 0.6791\n",
      "Epoch 149/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7909 - accuracy: 0.6748\n",
      "Epoch 00149: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 0.7909 - accuracy: 0.6748 - val_loss: 0.7912 - val_accuracy: 0.6776\n",
      "Epoch 150/150\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.6766\n",
      "Epoch 00150: val_accuracy did not improve from 0.68664\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 0.7879 - accuracy: 0.6766 - val_loss: 0.7857 - val_accuracy: 0.6767\n"
     ]
    }
   ],
   "source": [
    "if train:\n",
    "    history = model.fit( x_train , y_train,\n",
    "            batch_size=2**14,\n",
    "            epochs=150,\n",
    "            validation_split=0.1,\n",
    "            shuffle = True,\n",
    "            sample_weight= w_train,\n",
    "            callbacks = [\n",
    "                EarlyStopping(verbose=True, patience=150, monitor='val_accuracy'),\n",
    "                ModelCheckpoint(model_output, monitor='val_accuracy', verbose=True, save_best_only=True)\n",
    "                ],\n",
    "            verbose=True\n",
    "            )\n",
    "    \n",
    "model.load_weights(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8e304-9b1b-4c97-bbb0-7962b57be59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f311d-7786-4945-81d4-72745ea06614",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array( f5['x_test'] )\n",
    "y_test = to_categorical ( np.array( f5['y_test'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2892ce1-8b6e-404d-9dc5-ee8f52a1504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7202fb-7ab6-4432-8c76-757b9c3d67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40a205-d849-479e-b49a-38fc0c74a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555cfd05-9cf2-4dac-9657-e750fc2e2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_test, batch_size=2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b3c21-4fdc-437a-9af9-96f1d34b90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(pred_test, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9c04d-8bf8-4092-a950-835c7a17712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_b = pred_test[:,0] [y_test[:,0] == 1]\n",
    "pc_b = pred_test[:,1] [y_test[:,0] == 1]\n",
    "pl_b = pred_test[:,2] [y_test[:,0] == 1]\n",
    "    \n",
    "pc_c = pred_test[:,1] [y_test[:,1] == 1]\n",
    "pb_c = pred_test[:,0] [y_test[:,1] == 1]\n",
    "    \n",
    "pl_l = pred_test[:,2] [y_test[:,2] == 1]\n",
    "pb_l = pred_test[:,0] [y_test[:,2] == 1]\n",
    "\n",
    "plt.Figure()\n",
    "\n",
    "plt.hist( pb_b/(pb_b+pl_b), range=(0,1), bins=1000, histtype='step' )\n",
    "plt.hist( pb_l/(pb_l+pl_l), range=(0,1), bins=1000, histtype='step' )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.Figure()\n",
    "\n",
    "plt.hist( pb_b/(pb_b+pc_b), range=(0,1), bins=1000, histtype='step' )\n",
    "plt.hist( pb_c/(pb_c+pc_c), range=(0,1), bins=1000, histtype='step' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7be025-a74d-414e-a967-ee1ae92c0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "_ = plotting.makeRoc(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4514fa-392f-4aff-b228-5d07d0c5782a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25914d1-157a-4090-971d-59590c68ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "#     plt.Figure()\n",
    "    \n",
    "    this_wgts = layer.get_weights()\n",
    "#     if len(this_wgts) < 1: continue\n",
    "    print(layer.get_config())\n",
    "    \n",
    "    for wgt in this_wgts:\n",
    "        print(wgt)\n",
    "        print()\n",
    "#     max_wgts = np.max(this_wgts)\n",
    "#     min_wgts = np.min(this_wgts)\n",
    "#     plt.hist(this_wgts, bins=100, range=(min_wgts, max_wgts))\n",
    "#     plt.xlabel(f'{layer.name}')\n",
    "#     plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc300e9b-5a29-4901-8604-19178e15f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad098d16-00df-485d-88ac-afe5e016f847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868db1ad-f37b-4bec-a51b-e5739d7833ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
